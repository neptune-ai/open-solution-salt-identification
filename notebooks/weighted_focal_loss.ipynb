{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import ipywidgets as ipy\n",
    "\n",
    "from common_blocks.augmentation import resize_pad_seq\n",
    "from common_blocks.utils import plot_list, read_images\n",
    "from common_blocks.models import weighted_focal_loss\n",
    "from common_blocks.metrics import compute_eval_metric\n",
    "\n",
    "METADATA_FILEPATH = 'YOUR/metadata.csv'\n",
    "OUT_OF_FOLD_TRAIN_RESULTS_FILEPATH = 'YOUR/validation_results.pkl'\n",
    "\n",
    "METADATA_FILEPATH = '/mnt/ml-team/minerva/open-solutions/salt/files/metadata.csv'\n",
    "OUT_OF_FOLD_TRAIN_RESULTS_FILEPATH = '/mnt/ml-team/minerva/open-solutions/salt/kuba/experiments/sal_1036_cv_829_lb_837/out_of_fold_train_predictions.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = np.array(Image.open(path))\n",
    "    return img\n",
    "\n",
    "def filter_size(sizes, size_range):\n",
    "    size_min, size_max = size_range\n",
    "    filtered_idx = []\n",
    "    for idx, tup in enumerate(sizes):\n",
    "        if size_min<=tup<=size_max:\n",
    "            filtered_idx.append(idx)\n",
    "    return filtered_idx\n",
    "\n",
    "image_prep = resize_pad_seq(102, 'edge', 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(METADATA_FILEPATH)\n",
    "\n",
    "oof_train = joblib.load(OUT_OF_FOLD_TRAIN_RESULTS_FILEPATH)\n",
    "ids = oof_train['ids']\n",
    "predictions = oof_train['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "predicted_maps, masks, images, iouts, sizes = [],[],[],[],[]\n",
    "for idx, pred in tqdm(zip(ids, predictions)):\n",
    "    row = metadata[metadata['id']==idx]\n",
    "    predicted_map = np.zeros((2,101,101))\n",
    "    predicted_map[0,:,:] = resize(pred[0,:,:],(101,101),mode='constant')\n",
    "    predicted_map[1,:,:] = resize(pred[1,:,:],(101,101),mode='constant')\n",
    "    predicted_mask = (predicted_map[1,:,:] > THRESHOLD).astype(int)\n",
    "    mask = (load_img(row.file_path_mask.values[0]) > 0).astype(int)\n",
    "    image = load_img(row.file_path_image.values[0])\n",
    "    iout = compute_eval_metric(mask, predicted_mask)\n",
    "    size = np.sum(mask)\n",
    "    images.append(image)\n",
    "    masks.append(mask)\n",
    "    predicted_maps.append(predicted_map)\n",
    "    iouts.append(iout)\n",
    "    sizes.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_idxs = filter_size(sizes, size_range=(1, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ipy.interact(idx = ipy.IntSlider(min=0,max=len(size_idxs)-1,value=0,step=1),\n",
    "              alpha = ipy.FloatSlider(min=0,max=1,value=1.0,step=0.05),\n",
    "              gamma = ipy.FloatSlider(min=0,max=10,value=0.0,step=0.1),\n",
    "              max_weight = ipy.FloatSlider(min=1,max=1000.0,value=100.0,step=1.0),\n",
    "              focus_threshold = ipy.FloatSlider(min=0,max=1,value=0.0,step=0.1),\n",
    "              use_size_weight = ipy.Checkbox(value=True),\n",
    "              use_border_weight = ipy.Checkbox(value=True),\n",
    "              border_size = ipy.IntSlider(min=0,max=30,value=10,step=1),\n",
    "              border_weight = ipy.FloatSlider(min=0,max=10.,value=10.0,step=0.25))\n",
    "def present(idx, alpha, gamma,focus_threshold,\n",
    "            max_weight,use_size_weight, use_border_weight,border_size, border_weight):\n",
    "    data_idx = size_idxs[idx]\n",
    "    predicted_map = predicted_maps[data_idx]\n",
    "    logit = np.log(predicted_map/(1.0-predicted_map))\n",
    "    output = np.expand_dims(logit,axis=0)\n",
    "    \n",
    "    mask = masks[data_idx]\n",
    "\n",
    "    target = np.zeros_like(output)\n",
    "    target[:,1,:,:] = mask\n",
    "    target[:,0,:,:] = (mask == 0).astype(np.uint8)\n",
    "\n",
    "    iout = iouts[data_idx]\n",
    "    output = Variable(torch.Tensor(output))\n",
    "    target = Variable(torch.Tensor(target))\n",
    "    image = images[data_idx]\n",
    "\n",
    "    focal_loss = weighted_focal_loss(output, target,\n",
    "                               alpha=alpha, gamma=gamma,\n",
    "                               max_weight=max_weight,\n",
    "                               use_size_weight=use_size_weight,\n",
    "                               use_border_weight=use_border_weight,\n",
    "                               focus_threshold=focus_threshold,\n",
    "                               border_size=border_size, border_weight=border_weight)\n",
    "    focal_loss = focal_loss.data.cpu().numpy()[0]\n",
    "        \n",
    "    bce_loss = torch.nn.BCEWithLogitsLoss()(output, target)\n",
    "    bce_loss = bce_loss.data.cpu().numpy()[0]\n",
    "    \n",
    "    print('BCE {:.4f}, Focal Loss {:.4f}, IOUT {:.2f}'.format(bce_loss, focal_loss, iout))\n",
    "    plot_list(images=[image, predicted_map[1,:,:]],labels=[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36",
   "language": "python",
   "name": "py_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
